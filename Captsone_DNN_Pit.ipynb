{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import numpy as np\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    x_min = x.min(axis = (1, 2), keepdims = True)\n",
    "    x_max = x.max(axis = (1, 2), keepdims = True)\n",
    "\n",
    "    return (x - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    \n",
    "    return x[:,:,:int(0.75*x.shape[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"/Users/michelkauffmann/Downloads\")\n",
    "u = preprocess(scale(loadmat('u_F_xyz_T1.mat')[\"u_F\"]))\n",
    "v = preprocess(scale(loadmat('v_F_xyz_T1.mat')[\"v_F\"]))\n",
    "w = preprocess(scale(loadmat('w_F_xyz_T1.mat')[\"w_F\"]))\n",
    "tau_11 = preprocess(loadmat('tau11_xyz_T1.mat')[\"tau11\"])\n",
    "tau_12 = preprocess(loadmat('tau12_xyz_T1.mat')[\"tau12\"])\n",
    "tau_13 = preprocess(loadmat('tau13_xyz_T1.mat')[\"tau13\"])\n",
    "tau_22 = preprocess(loadmat('tau22_xyz_T1.mat')[\"tau22\"])\n",
    "tau_23 = preprocess(loadmat('tau23_xyz_T1.mat')[\"tau23\"])\n",
    "tau_33 = preprocess(loadmat('tau33_xyz_T1.mat')[\"tau33\"])\n",
    "tke = preprocess(scale(loadmat(\"TKE_F_xyz_T1.mat\")[\"TKE_F\"]))\n",
    "theta = preprocess(scale(loadmat(\"theta_F_xyz_T1.mat\")[\"theta_F\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taus = False\n",
    "significance = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generae Input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create Input dataset (u, v, w, TKE, $\\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([u, v, w, tke, theta])\n",
    "x = np.transpose(x, [1, 2, 3, 0])\n",
    "x = np.pad(x, ((3,3), (3,3), (3,3), (0,0)), 'constant', constant_values = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129996e64f8c48eb9c008527fee24fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=146), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample = []\n",
    "size = 3\n",
    "y_tau_11 = []\n",
    "y_tau_12 = []\n",
    "y_tau_13 = []\n",
    "y_tau_22 = []\n",
    "y_tau_23 = []\n",
    "y_tau_33 = []\n",
    "for i in tqdm_notebook(range(size, x.shape[0] - size)):\n",
    "    for j in range(size, x.shape[1] - size):\n",
    "        for k in range(size, x.shape[2] - size):\n",
    "            sample.append(x[i - size: i + size + 1, j - size: j + size + 1, k - size: k + size + 1, :])\n",
    "            y_tau_11.append(tau_11[i - size][j - size][k - size])\n",
    "            y_tau_12.append(tau_12[i - size][j - size][k - size])\n",
    "            y_tau_13.append(tau_13[i - size][j - size][k - size])\n",
    "            y_tau_22.append(tau_22[i - size][j - size][k - size])\n",
    "            y_tau_23.append(tau_23[i - size][j - size][k - size])\n",
    "            y_tau_33.append(tau_33[i - size][j - size][k - size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784896, 7, 7, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.stack(sample, axis = 0)\n",
    "print(x.shape)\n",
    "\n",
    "y_tau_11 = np.array(y_tau_11)\n",
    "y_tau_12 = np.array(y_tau_12)\n",
    "y_tau_13 = np.array(y_tau_13)\n",
    "y_tau_22 = np.array(y_tau_22)\n",
    "y_tau_23 = np.array(y_tau_23)\n",
    "y_tau_33 = np.array(y_tau_33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create Input Dataset (u, v, w, $\\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784896, 7, 7, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "x_theta = np.delete(x, 3, 4)\n",
    "print(x_theta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create Input Dataset (u, v, w, TKE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784896, 7, 7, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "x_tke = np.delete(x, 4, 4)\n",
    "print(x_tke.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Create Dataset (u, v, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784896, 7, 7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "x_base = np.delete(x, (3,4), 4)\n",
    "print(x_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    \n",
    "    def __init__(self, activation, initializer, regularizer, x_train, y_train, epochs, batch_size, input_shape, val_split):\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.regularizer = regularizer\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.val_split = val_split\n",
    "        \n",
    "        pass \n",
    "    \n",
    "    def create_model(self):\n",
    "        model = keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape = self.input_shape),\n",
    "            tf.keras.layers.Dense(256, \n",
    "                             activation = self.activation, \n",
    "                             kernel_regularizer = self.regularizer, \n",
    "                             kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(128, \n",
    "                             activation = self.activation, \n",
    "                             kernel_regularizer = self.regularizer, \n",
    "                             kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(64, \n",
    "                             activation = self.activation, \n",
    "                             kernel_regularizer = self.regularizer, \n",
    "                             kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(32, \n",
    "                             activation = self.activation, \n",
    "                             kernel_regularizer = self.regularizer, \n",
    "                             kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def callbacks(self):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                               min_delta = 0.001,\n",
    "                                               patience = 0,\n",
    "                                               verbose = 0)\n",
    "        \n",
    "        return early_stopping\n",
    "    \n",
    "    def run_model(self):\n",
    "        model = self.create_model()\n",
    "        model.compile(optimizer = tf.train.AdamOptimizer(), \n",
    "              loss = \"mse\")\n",
    "              #metrics = ['mse'])\n",
    "        \n",
    "        history = model.fit(self.x_train, self.y_train, \n",
    "                    epochs = self.epochs, \n",
    "                    validation_split = self.val_split, \n",
    "                    batch_size =  self.batch_size,\n",
    "                    verbose = 1)\n",
    "                    #callbacks = [self.callbacks()])\n",
    "        \n",
    "        return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 502472 samples, validate on 125618 samples\n",
      "Epoch 1/50\n",
      "502472/502472 [==============================] - 10s 20us/step - loss: 0.0426 - val_loss: 1.1636e-04\n",
      "Epoch 2/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 0.0018 - val_loss: 2.3105e-05\n",
      "Epoch 3/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 4.8395e-04 - val_loss: 2.3033e-05\n",
      "Epoch 4/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.7809e-04 - val_loss: 1.1362e-05\n",
      "Epoch 5/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 7.5160e-05 - val_loss: 8.6811e-06\n",
      "Epoch 6/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 6.1828e-05 - val_loss: 8.6806e-06\n",
      "Epoch 7/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 5.2765e-05 - val_loss: 8.6842e-06\n",
      "Epoch 8/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 4.5648e-05 - val_loss: 8.6753e-06\n",
      "Epoch 9/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 3.9826e-05 - val_loss: 8.6467e-06\n",
      "Epoch 10/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 3.6171e-05 - val_loss: 8.7660e-06\n",
      "Epoch 11/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 3.2246e-05 - val_loss: 8.8341e-06\n",
      "Epoch 12/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 2.9187e-05 - val_loss: 8.8123e-06\n",
      "Epoch 13/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 2.6176e-05 - val_loss: 8.8007e-06\n",
      "Epoch 14/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 2.4840e-05 - val_loss: 8.7860e-06\n",
      "Epoch 15/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 2.3261e-05 - val_loss: 8.7675e-06\n",
      "Epoch 16/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 2.2119e-05 - val_loss: 8.7513e-06\n",
      "Epoch 17/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 2.0903e-05 - val_loss: 8.7126e-06\n",
      "Epoch 18/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.9381e-05 - val_loss: 8.7249e-06\n",
      "Epoch 19/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.7687e-05 - val_loss: 8.6981e-06\n",
      "Epoch 20/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.4514e-05 - val_loss: 8.7189e-06\n",
      "Epoch 21/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.2115e-05 - val_loss: 8.7049e-06\n",
      "Epoch 22/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.1281e-05 - val_loss: 8.9586e-06\n",
      "Epoch 23/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0941e-05 - val_loss: 9.0711e-06\n",
      "Epoch 24/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0795e-05 - val_loss: 8.9572e-06\n",
      "Epoch 25/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0654e-05 - val_loss: 8.7962e-06\n",
      "Epoch 26/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0579e-05 - val_loss: 8.7260e-06\n",
      "Epoch 27/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0542e-05 - val_loss: 8.6746e-06\n",
      "Epoch 28/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0327e-05 - val_loss: 8.6031e-06\n",
      "Epoch 29/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0280e-05 - val_loss: 8.5545e-06\n",
      "Epoch 30/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0325e-05 - val_loss: 8.5444e-06\n",
      "Epoch 31/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0270e-05 - val_loss: 8.4264e-06\n",
      "Epoch 32/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0122e-05 - val_loss: 8.4013e-06\n",
      "Epoch 33/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 1.0089e-05 - val_loss: 8.3280e-06\n",
      "Epoch 34/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0002e-05 - val_loss: 8.3374e-06\n",
      "Epoch 35/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8052e-06 - val_loss: 8.3534e-06\n",
      "Epoch 36/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.7076e-06 - val_loss: 8.1874e-06\n",
      "Epoch 37/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 9.5963e-06 - val_loss: 8.2618e-06\n",
      "Epoch 38/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.5408e-06 - val_loss: 8.1614e-06\n",
      "Epoch 39/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 9.4902e-06 - val_loss: 8.0621e-06\n",
      "Epoch 40/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.3559e-06 - val_loss: 8.0944e-06\n",
      "Epoch 41/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.3237e-06 - val_loss: 8.0462e-06\n",
      "Epoch 42/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.1893e-06 - val_loss: 7.9601e-06\n",
      "Epoch 43/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.1940e-06 - val_loss: 7.8914e-06\n",
      "Epoch 44/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.1129e-06 - val_loss: 7.8889e-06\n",
      "Epoch 45/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.0181e-06 - val_loss: 7.7881e-06\n",
      "Epoch 46/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 8.9886e-06 - val_loss: 7.8934e-06\n",
      "Epoch 47/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 8.8910e-06 - val_loss: 7.7244e-06\n",
      "Epoch 48/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 8.8486e-06 - val_loss: 7.6229e-06\n",
      "Epoch 49/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 8.8528e-06 - val_loss: 7.5844e-06\n",
      "Epoch 50/50\n",
      "502472/502472 [==============================] - 8s 17us/step - loss: 8.8113e-06 - val_loss: 7.4503e-06\n",
      "R^2: 0.1885\n",
      "Correlation: 0.4872\n",
      "\n",
      "Train on 502472 samples, validate on 125618 samples\n",
      "Epoch 1/50\n",
      "502472/502472 [==============================] - 10s 19us/step - loss: 0.0392 - val_loss: 2.4130e-04\n",
      "Epoch 2/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 0.0011 - val_loss: 9.6527e-05\n",
      "Epoch 3/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 3.1396e-04 - val_loss: 1.4730e-05\n",
      "Epoch 4/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1243e-04 - val_loss: 9.3330e-06\n",
      "Epoch 5/50\n",
      "502472/502472 [==============================] - 9s 19us/step - loss: 3.8866e-05 - val_loss: 1.2692e-05\n",
      "Epoch 6/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 2.0362e-05 - val_loss: 9.2758e-06\n",
      "Epoch 7/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.4551e-05 - val_loss: 9.2762e-06\n",
      "Epoch 8/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.3177e-05 - val_loss: 9.2758e-06\n",
      "Epoch 9/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.2444e-05 - val_loss: 9.2758e-06\n",
      "Epoch 10/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1963e-05 - val_loss: 9.2781e-06\n",
      "Epoch 11/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1925e-05 - val_loss: 9.2768e-06\n",
      "Epoch 12/50\n",
      "502472/502472 [==============================] - 9s 19us/step - loss: 1.1669e-05 - val_loss: 9.2769e-06\n",
      "Epoch 13/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1515e-05 - val_loss: 9.2757e-06\n",
      "Epoch 14/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1354e-05 - val_loss: 9.2758e-06\n",
      "Epoch 15/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.1160e-05 - val_loss: 9.2756e-06\n",
      "Epoch 16/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0965e-05 - val_loss: 9.2757e-06\n",
      "Epoch 17/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0885e-05 - val_loss: 9.2758e-06\n",
      "Epoch 18/50\n",
      "502472/502472 [==============================] - 9s 19us/step - loss: 1.0762e-05 - val_loss: 9.2765e-06\n",
      "Epoch 19/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0635e-05 - val_loss: 9.2758e-06\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0589e-05 - val_loss: 9.2768e-06\n",
      "Epoch 21/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0509e-05 - val_loss: 9.2764e-06\n",
      "Epoch 22/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0444e-05 - val_loss: 9.2756e-06\n",
      "Epoch 23/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0308e-05 - val_loss: 9.2759e-06\n",
      "Epoch 24/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0318e-05 - val_loss: 9.2759e-06\n",
      "Epoch 25/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0195e-05 - val_loss: 9.2757e-06\n",
      "Epoch 26/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0049e-05 - val_loss: 9.2758e-06\n",
      "Epoch 27/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0127e-05 - val_loss: 9.2757e-06\n",
      "Epoch 28/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0041e-05 - val_loss: 9.2759e-06\n",
      "Epoch 29/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0049e-05 - val_loss: 9.2970e-06\n",
      "Epoch 30/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0041e-05 - val_loss: 9.2763e-06\n",
      "Epoch 31/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9701e-06 - val_loss: 9.2886e-06\n",
      "Epoch 32/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 1.0006e-05 - val_loss: 9.2793e-06\n",
      "Epoch 33/50\n",
      "502472/502472 [==============================] - 9s 17us/step - loss: 9.9793e-06 - val_loss: 9.2994e-06\n",
      "Epoch 34/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9760e-06 - val_loss: 9.2763e-06\n",
      "Epoch 35/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9712e-06 - val_loss: 9.2758e-06\n",
      "Epoch 36/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9712e-06 - val_loss: 9.2781e-06\n",
      "Epoch 37/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9583e-06 - val_loss: 9.2774e-06\n",
      "Epoch 38/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8669e-06 - val_loss: 9.2775e-06\n",
      "Epoch 39/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9347e-06 - val_loss: 9.2757e-06\n",
      "Epoch 40/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8737e-06 - val_loss: 9.2779e-06\n",
      "Epoch 41/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9025e-06 - val_loss: 9.2766e-06\n",
      "Epoch 42/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8573e-06 - val_loss: 9.2768e-06\n",
      "Epoch 43/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.9167e-06 - val_loss: 9.2765e-06\n",
      "Epoch 44/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8922e-06 - val_loss: 9.2781e-06\n",
      "Epoch 45/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8480e-06 - val_loss: 9.2764e-06\n",
      "Epoch 46/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8745e-06 - val_loss: 9.2757e-06\n",
      "Epoch 47/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8819e-06 - val_loss: 9.2824e-06\n",
      "Epoch 48/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8225e-06 - val_loss: 9.2783e-06\n",
      "Epoch 49/50\n",
      "502472/502472 [==============================] - 9s 19us/step - loss: 9.8180e-06 - val_loss: 9.2757e-06\n",
      "Epoch 50/50\n",
      "502472/502472 [==============================] - 9s 18us/step - loss: 9.8473e-06 - val_loss: 9.2760e-06\n",
      "R^2: -0.0001\n",
      "Correlation: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk2573/miniconda3/envs/dlenv/lib/python3.6/site-packages/numpy/lib/function_base.py:2400: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/pk2573/miniconda3/envs/dlenv/lib/python3.6/site-packages/numpy/lib/function_base.py:2401: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a1b5d2d7118a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if significance:\n",
    "    activation = tf.nn.relu\n",
    "    initializer = None\n",
    "    regularizer = None\n",
    "    epochs = 50\n",
    "    batch_size = 10000\n",
    "    val_split = 0.2\n",
    "\n",
    "    datasets = [x_base, x_tke, x_theta]\n",
    "    fig = plt.figure(figsize = (20, 6))\n",
    "    results = {}\n",
    "    i = 1\n",
    "    for x in datasets:\n",
    "        mask =  np.random.rand(x.shape[0]) < 0.80\n",
    "        y_train, y_test = y_tau_11[mask], y_tau_11[~mask]\n",
    "        x_train, x_test = x[mask,:,:,:,:], x[~mask,:,:,:,:]\n",
    "\n",
    "        input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3], x_train.shape[4])\n",
    "        model = DNN(activation, initializer, regularizer, x_train, y_train, epochs, batch_size, input_shape, val_split)        \n",
    "        history, model = model.run_model()\n",
    "        \n",
    "        fig.add_subplot(1, len(datasets), i)\n",
    "        plt.plot(history.epoch, np.array(history.history['loss']), label = 'Train Loss')\n",
    "        plt.plot(history.epoch, np.array(history.history['val_loss']), label = 'Val loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Square Error')\n",
    "        plt.ylim((0,0.00005))\n",
    "        plt.legend()\n",
    "\n",
    "        y_pred = model.predict(x_test).flatten()\n",
    "        y_true = y_test\n",
    "        print(\"R^2: %.4f\" % r2_score(y_true, y_pred))\n",
    "        print(\"Correlation: %.4f\\n\" % np.corrcoef(y_pred, y_true)[0, 1])\n",
    "        results[np.corrcoef(y_pred, y_true)[0, 1]] = x\n",
    "        i += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_best = results[max(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_taus:\n",
    "    taus = [y_tau_11, y_tau_12, y_tau_13, y_tau_22, y_tau_23, y_tau_33]\n",
    "else:\n",
    "    taus = [y_tau_12, y_tau_13, y_tau_23]\n",
    "    \n",
    "activation = tf.nn.relu\n",
    "initializer = None\n",
    "regularizer = None\n",
    "epochs = 500\n",
    "batch_size = 10000\n",
    "input_shape = (x_best.shape[1], x_best.shape[2], x_best.shape[3], x_best.shape[4])\n",
    "val_split = 0.2\n",
    "\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "\n",
    "i = 1\n",
    "for y in taus:\n",
    "    mask =  np.random.rand(x.shape[0]) < 0.80\n",
    "    x_train, x_test = x_best[mask,:,:,:,:], x_best[~mask,:,:,:,:]\n",
    "    y_train, y_test = y[mask], y[~mask]\n",
    "    \n",
    "    model = DNN(activation, initializer, regularizer, x_train, y_train, epochs, batch_size, input_shape, filter_size, val_split)\n",
    "    history, model = model.run_model()\n",
    "    fig.add_subplot(2, int(len(taus)/2), i)\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']), label = 'Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']), label = 'Val loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.legend()\n",
    "    \n",
    "    y_pred = model.predict(x_test).flatten()\n",
    "    y_true = y_test\n",
    "    print(\"R^2: %.4f\" % r2_score(y_true, y_pred))\n",
    "    print(\"Correlation: %.4f\\n\" % np.corrcoef(y_pred, y_true)[0, 1])\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
