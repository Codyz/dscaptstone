{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "import zipfile\n",
    "from tensorflow.keras.models import model_from_json\n",
    "!pip install tqdm\n",
    "!pip install h5py\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "\n",
    "    return (x - np.mean(x)) / np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    \n",
    "    return x[:,:,:int(0.75*x.shape[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(x, switch):\n",
    "    temp = []\n",
    "    size = int(x.shape[0] / 5)\n",
    "    for i in range(5):\n",
    "        temp.append(x[i * size:(i + 1) * size])\n",
    "    x = np.array(temp)\n",
    "    \n",
    "    if switch:\n",
    "        x = np.reshape(x, (5,-1))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/pk2573/Capstone_Data/Re1243Fr20/coarse8\")\n",
    "u = preprocess(scale(loadmat('u_F_xyz_T1.mat')[\"u_F\"]))\n",
    "v = preprocess(scale(loadmat('v_F_xyz_T1.mat')[\"v_F\"]))\n",
    "w = preprocess(scale(loadmat('w_F_xyz_T1.mat')[\"w_F\"]))\n",
    "tau_12 = preprocess(scale(loadmat('tau12_F_xyz_T1.mat')[\"tau12\"]))\n",
    "tau_13 = preprocess(scale(loadmat('tau13_F_xyz_T1.mat')[\"tau13\"]))\n",
    "tau_23 = preprocess(scale(loadmat('tau23_F_xyz_T1.mat')[\"tau23\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taus = False\n",
    "significance = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 96, 56, 3)\n",
      "(5, 29, 96, 56, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([u, v, w])\n",
    "x = np.transpose(x, [1, 2, 3, 0])\n",
    "print(x.shape)\n",
    "x = cut(x, False)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 29, 96, 56)\n",
      "(5, 29, 96, 56, 1)\n",
      "(5, 29, 96, 56, 1)\n",
      "(5, 29, 96, 56, 1)\n"
     ]
    }
   ],
   "source": [
    "tau_12 = cut(tau_12, False)\n",
    "print(tau_12.shape)\n",
    "tau_12 = np.reshape(tau_12, (tau_12.shape[0], tau_12.shape[1], tau_12.shape[2], tau_12.shape[3], 1))\n",
    "print(tau_12.shape)\n",
    "tau_13 = cut(tau_13, False)\n",
    "tau_13 = np.reshape(tau_13, (tau_13.shape[0], tau_13.shape[1], tau_13.shape[2], tau_13.shape[3], 1))\n",
    "print(tau_13.shape)\n",
    "tau_23 = cut(tau_23, False)\n",
    "tau_23 = np.reshape(tau_23, (tau_23.shape[0], tau_23.shape[1], tau_23.shape[2], tau_23.shape[3], 1))\n",
    "print(tau_23.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    \n",
    "    def __init__(self, activation, initializer, regularizer, x_train, y_train, epochs, batch_size, input_shape, filter_size):\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.regularizer = regularizer\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.filter = filter_size\n",
    "        \n",
    "        pass \n",
    "    \n",
    "    def create_model(self):\n",
    "        model = keras.Sequential([\n",
    "            tf.keras.layers.Conv3D(128,\n",
    "                             kernel_size = self.filter,\n",
    "                             activation = self.activation,\n",
    "                             input_shape = input_shape,   \n",
    "                             padding = \"same\",\n",
    "                             kernel_regularizer = self.regularizer,\n",
    "                             data_format = 'channels_last'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv3D(64,\n",
    "                             kernel_size = (1,1,1),\n",
    "                             activation = self.activation,\n",
    "                             padding = \"same\",\n",
    "                             kernel_regularizer = self.regularizer),\n",
    "             tf.keras.layers.Dropout(0.2),\n",
    "             tf.keras.layers.Conv3D(32,\n",
    "                             kernel_size = (1,1,1),\n",
    "                             activation = self.activation,\n",
    "                             padding = \"same\",\n",
    "                             kernel_regularizer = self.regularizer),\n",
    "             tf.keras.layers.Conv3D(1,\n",
    "                             kernel_size = (1,1,1),\n",
    "                             activation = self.activation,\n",
    "                             padding = \"same\",\n",
    "                             kernel_regularizer = self.regularizer),\n",
    "        ])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_model(self):\n",
    "        model = self.create_model()\n",
    "        model.compile(optimizer = tf.train.AdamOptimizer(), \n",
    "              loss = \"mse\")\n",
    "        \n",
    "        model.summary()\n",
    "            \n",
    "        history = model.fit(self.x_train, self.y_train, \n",
    "                    epochs = self.epochs, \n",
    "                    batch_size =  self.batch_size,\n",
    "                    verbose = 1)\n",
    "        \n",
    "        return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 29, 96, 56, 128)   131840    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 96, 56, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 29, 96, 56, 64)    8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 96, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 29, 96, 56, 32)    2080      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 29, 96, 56, 1)     33        \n",
      "=================================================================\n",
      "Total params: 142,209\n",
      "Trainable params: 142,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 1.3327\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.2822\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.2673\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.2464\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.2331\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.2223\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.2144\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 1.1995\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.1866\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.1710\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.1535\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.1398\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.1282\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.1147\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.1061\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.0952\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0867\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0798\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 1.0719\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.0606\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.0524\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0444\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.0402\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0332\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0292\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.0237\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.0185\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.0135\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.0092\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1.0056\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.0034\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.9992\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9941\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9857\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9869\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9822\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.9769\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9815\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9841\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9769\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9746\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.9693\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9675\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9643\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.9683\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9630\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.9639\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.9691\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9735\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9784\n",
      "R^2: 0.2458\n",
      "Correlation: 0.5200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = tf.nn.relu\n",
    "initializer = None\n",
    "regularizer = None\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "filter_size = (7,7,7)\n",
    "\n",
    "x, tau_12 = shuffle(x, tau_12)\n",
    "x_train, x_test = x[1:], x[0]\n",
    "y_train, y_test = tau_12[1:], tau_12[0]\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3], x_train.shape[4])\n",
    "model = CNN(activation, initializer, regularizer, x_train, y_train, epochs, batch_size, input_shape, filter_size)\n",
    "history, model = model.run_model()\n",
    "\n",
    "x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3]))\n",
    "y_pred = model.predict(x_test).flatten()\n",
    "\n",
    "y_true = y_test.flatten()\n",
    "print(\"R^2: %.4f\" % r2_score(y_true, y_pred))\n",
    "print(\"Correlation: %.4f\\n\" % np.corrcoef(y_pred, y_true)[0, 1])\n",
    "\n",
    "del x_train\n",
    "del x_test\n",
    "del y_train\n",
    "del y_test\n",
    "del model\n",
    "del y_pred\n",
    "del y_true\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
