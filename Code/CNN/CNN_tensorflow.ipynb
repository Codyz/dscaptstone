{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "\n",
    "def tranform_to_sampel(raw,new):\n",
    "    num = 0\n",
    "    for i in arange(0,s1,stride):\n",
    "        if i+n1>=s1:\n",
    "            l1 = list(arange(i,s1))\n",
    "            l2 = list(arange(0,n1-len(l1)))\n",
    "            il = l1+l2\n",
    "        else:\n",
    "            il = list(arange(i,i+n1))\n",
    "        for j in range(0,s2,stride):\n",
    "            if j+n2>=s2:\n",
    "                l1 = list(arange(j,s2))\n",
    "                l2 = list(arange(0,n2-len(l1)))\n",
    "                jl = l1+l2\n",
    "            else:\n",
    "                jl =list(arange(j,j+n2)) \n",
    "                \n",
    "            new[num,:,:,:]= raw[il,:,:][:,jl,:]\n",
    "            if num == 0:\n",
    "                print(il,jl)            \n",
    "            num = num + 1\n",
    "\n",
    "    return new\n",
    "\n",
    "def tranform_to_target(raw,new,out):\n",
    "    num = 0\n",
    "    for i in arange(0,s1,stride):\n",
    "        if i+n1>=s1:\n",
    "            l1 = list(arange(i,s1))\n",
    "            l2 = list(arange(0,n1-len(l1)))\n",
    "            il = l1+l2\n",
    "        else:\n",
    "            il = list(arange(i,i+n1))\n",
    "        for j in range(0,s2,stride):\n",
    "            if j+n2>=s2:\n",
    "                l1 = list(arange(j,s2))\n",
    "                l2 = list(arange(0,n2-len(l1)))\n",
    "                jl = l1+l2\n",
    "            else:\n",
    "                jl =list(arange(j,j+n2)) \n",
    "                \n",
    "            new[num,:,:,:]= raw[il,:,:][:,jl,:]\n",
    "            out[num,:] = new[num,:,:,:][3,3,:]\n",
    "            if num == 0:\n",
    "                print(il,jl)            \n",
    "            num = num + 1\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_u = scipy.io.loadmat(\"u_F_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_v = scipy.io.loadmat(\"v_F_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_w = scipy.io.loadmat(\"w_F_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau11 = scipy.io.loadmat(\"tau11_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau12 = scipy.io.loadmat(\"tau12_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau13 = scipy.io.loadmat(\"tau13_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau22 = scipy.io.loadmat(\"tau22_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau23 = scipy.io.loadmat(\"tau23_xyz_T1.mat\", mdict=None, appendmat=True)\n",
    "input_tau33 = scipy.io.loadmat(\"tau33_xyz_T1.mat\", mdict=None, appendmat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_F = input_u['u_F']\n",
    "v_F = input_v['v_F']\n",
    "w_F = input_w['w_F']\n",
    "tau11 = input_tau11['tau11']\n",
    "tau12 = input_tau12['tau12']\n",
    "tau13 = input_tau13['tau13']\n",
    "tau22 = input_tau22['tau22']\n",
    "tau23 = input_tau23['tau23']\n",
    "tau33 = input_tau33['tau33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "s1,s2,s3 = tau11.shape\n",
    "n1 = 7\n",
    "n2 = 7\n",
    "n3 = s3\n",
    "\n",
    "stride = 1\n",
    "num = 0\n",
    "for i in arange(0,s1,stride):\n",
    "    for j in range(0,s2,stride):\n",
    "        num = num +1\n",
    "\n",
    "ini = np.zeros((num,n1,n2,n3))\n",
    "newy = np.zeros((num,n3))\n",
    "#transform into small box\n",
    "vf = np.float32(tranform_to_sampel(v_F,ini))\n",
    "uf = np.float32(tranform_to_sampel(u_F,ini))\n",
    "wf = np.float32(tranform_to_sampel(w_F,ini))\n",
    "\n",
    "y11 = np.float32(tranform_to_target(tau11,ini,newy))\n",
    "\n",
    "y12= np.float32(tranform_to_target(tau12,ini,newy))\n",
    "y13= np.float32(tranform_to_target(tau13,ini,newy))\n",
    "y22= np.float32(tranform_to_target(tau22,ini,newy))\n",
    "y23= np.float32(tranform_to_target(tau23,ini,newy))\n",
    "y33= np.float32(tranform_to_target(tau33,ini,newy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain11 = np.reshape(y11, (y11.shape[0], -1))\n",
    "batch_size = 128\n",
    "nb_epoch = 250\n",
    "\n",
    "#input_shape = (n1,n2,n3)\n",
    "kernel_size = [3, 3]\n",
    "pool_size = [2, 2]\n",
    "outsize = n3\n",
    "nb_filters = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    #first model\n",
    "    visible1 = tf.reshape(features['u'], [-1, 7, 7, 75])\n",
    "    ##Input(shape=(vf.shape[1],vf.shape[2],vf.shape[3]))\n",
    "    conv11 = tf.layers.conv2d(inputs=visible1, filters=nb_filters, kernel_size=kernel_size, \n",
    "                            padding=\"valid\", activation=tf.nn.relu)\n",
    "    conv12 = tf.layers.conv2d(inputs=conv11, filters=nb_filters, kernel_size=kernel_size, \n",
    "                            padding='valid', activation=tf.nn.relu)\n",
    "    pool12 = tf.layers.max_pooling2d(inputs=conv12, pool_size=pool_size, strides=2)\n",
    "    flat1 = tf.layers.flatten(inputs=pool12)\n",
    "    drop1 = tf.layers.dropout(inputs=flat1, rate=0.2)\n",
    "    \n",
    "    visible2 = tf.reshape(features['v'], [-1, 7, 7, 75])\n",
    "    #Input(shape=(vf.shape[1],vf.shape[2],vf.shape[3]))\n",
    "    conv21 = tf.layers.conv2d(inputs=visible2, filters=nb_filters, kernel_size=kernel_size, \n",
    "                            padding='valid', activation=tf.nn.relu)\n",
    "    conv22 = tf.layers.conv2d(inputs=conv21, filters=nb_filters, kernel_size=kernel_size, \n",
    "                            padding='valid', activation=tf.nn.relu)\n",
    "    pool22 = tf.layers.max_pooling2d(inputs=conv22, pool_size=pool_size, strides=2)\n",
    "    flat2 = tf.layers.flatten(inputs=pool22)\n",
    "    drop2 = tf.layers.dropout(inputs=flat2, rate=0.2)\n",
    "    \n",
    "    visible3 = tf.reshape(features['w'], [-1, 7, 7, 75])\n",
    "    #Input(shape=(vf.shape[1],vf.shape[2],vf.shape[3]))\n",
    "    conv31 = tf.layers.conv2d(inputs=visible3, filters=nb_filters, kernel_size=kernel_size, \n",
    "                            padding='valid', activation=tf.nn.relu)\n",
    "    conv32 = tf.layers.conv2d(inputs=conv31, filters=nb_filters, kernel_size=kernel_size,\n",
    "                            padding='valid', activation=tf.nn.relu)\n",
    "    pool32 = tf.layers.max_pooling2d(inputs=conv32, pool_size=pool_size, strides=2)\n",
    "    flat3 = tf.layers.flatten(inputs=pool32)\n",
    "    drop3 = tf.layers.dropout(inputs=flat3, rate=0.2)\n",
    "    \n",
    "    merge = tf.concat([drop1, drop2,drop3], 1)\n",
    "    hidden1 = tf.layers.dense(inputs=merge, units=64, activation=tf.nn.relu)\n",
    "    hiddrop = tf.layers.dropout(inputs=hidden1, rate=0.3)\n",
    "    hidden2 = tf.layers.dense(inputs=hiddrop, units=128, activation=tf.nn.relu)\n",
    "    y_pred = tf.layers.dense(inputs=hidden2, units=outsize, activation=tf.nn.relu)\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(labels, y_pred)\n",
    "    \n",
    "    predictions = {\n",
    "        \"matrix\": y_pred,\n",
    "        \"loss\": tf.metrics.mean_squared_error(labels, y_pred, name=\"mse_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    grads = tf.gradients(loss, tf.trainable_variables())\n",
    "    grads = list(zip(grads, tf.trainable_variables()))\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.name, var)\n",
    "    # Summarize all gradients\n",
    "    for grad, var in grads:\n",
    "        tf.summary.histogram(var.name + '/gradient', grad)\n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    summary_hook = tf.train.SummarySaverHook(\n",
    "        save_steps=100,\n",
    "        summary_op=merged_summary_op)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks=[summary_hook])\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"mse\": tf.metrics.mean_absolute_error(labels=labels, predictions=y_pred)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_service': None, '_model_dir': './cnn_model_log', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C44AD4A2E8>, '_tf_random_seed': None, '_is_chief': True, '_master': '', '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_session_config': None, '_task_type': 'worker', '_num_ps_replicas': 0}\n"
     ]
    }
   ],
   "source": [
    "nn = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"./cnn_model_log\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"loss\": \"mse_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "    \n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'u': uf, 'v': vf, 'w': wf},\n",
    "    y=ytrain11,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2d/kernel:0 is illegal; using conv2d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d/bias:0 is illegal; using conv2d/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0 is illegal; using conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0 is illegal; using conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/kernel:0 is illegal; using conv2d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/bias:0 is illegal; using conv2d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/kernel:0 is illegal; using conv2d_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/bias:0 is illegal; using conv2d_3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/kernel:0 is illegal; using conv2d_4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/bias:0 is illegal; using conv2d_4/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/kernel:0 is illegal; using conv2d_5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/bias:0 is illegal; using conv2d_5/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d/kernel:0/gradient is illegal; using conv2d/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d/bias:0/gradient is illegal; using conv2d/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0/gradient is illegal; using conv2d_1/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0/gradient is illegal; using conv2d_1/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/kernel:0/gradient is illegal; using conv2d_2/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/bias:0/gradient is illegal; using conv2d_2/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/kernel:0/gradient is illegal; using conv2d_3/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/bias:0/gradient is illegal; using conv2d_3/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/kernel:0/gradient is illegal; using conv2d_4/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/bias:0/gradient is illegal; using conv2d_4/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/kernel:0/gradient is illegal; using conv2d_5/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/bias:0/gradient is illegal; using conv2d_5/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0/gradient is illegal; using dense/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0/gradient is illegal; using dense/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0/gradient is illegal; using dense_1/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0/gradient is illegal; using dense_1/bias_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0/gradient is illegal; using dense_2/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0/gradient is illegal; using dense_2/bias_0/gradient instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./cnn_model_log\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.004180347, step = 1\n",
      "INFO:tensorflow:global_step/sec: 23.9701\n",
      "INFO:tensorflow:loss = 0.0034298897, step = 101 (4.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2774\n",
      "INFO:tensorflow:loss = 0.0032555894, step = 201 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5173\n",
      "INFO:tensorflow:loss = 0.0028450857, step = 301 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3473\n",
      "INFO:tensorflow:loss = 0.002387675, step = 401 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2837\n",
      "INFO:tensorflow:loss = 0.0021805284, step = 501 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1481\n",
      "INFO:tensorflow:loss = 0.0019596973, step = 601 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1921\n",
      "INFO:tensorflow:loss = 0.0020240275, step = 701 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5271\n",
      "INFO:tensorflow:loss = 0.0019694858, step = 801 (4.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6199\n",
      "INFO:tensorflow:loss = 0.0018269995, step = 901 (4.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6259\n",
      "INFO:tensorflow:loss = 0.001747286, step = 1001 (4.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3601\n",
      "INFO:tensorflow:loss = 0.0019594454, step = 1101 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1638\n",
      "INFO:tensorflow:loss = 0.0016016166, step = 1201 (3.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3537\n",
      "INFO:tensorflow:loss = 0.0018118706, step = 1301 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.392\n",
      "INFO:tensorflow:loss = 0.0016862103, step = 1401 (3.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into ./cnn_model_log\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0015793948.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c44ad4a588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(input_fn=train_input_fn,steps=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
